import torch
from collections import deque
from segment_anything import sam_model_registry, SamAutomaticMaskGenerator
import numpy as np
import cv2

class object_finder:
    def __init__(self):
        self.sam_checkpoint = "resources/sam_vit_h_4b8939.pth" # Path to the checkpoint file of the instance segmentation model
        self.model_type = "vit_h" # Type of the instance segmentation model (e.g., ViT-H)
        self.device = None # Device to run the model on (CPU or CUDA)
        self.sam = None # Instance segmentation model
        self.mask_generator = None # Mask generator for creating instance masks
        self.frame_queue = deque() # Queue of frames that need to be segmented
        self.initialize() # Initialize the object finder

    def initialize(self):
        if torch.cuda.is_available():
            self.device = "cuda" # Use CUDA if available for faster computation
        else:
            self.device = "cpu"

        # Load the instance segmentation model
        self.sam = sam_model_registry[self.model_type](checkpoint=self.sam_checkpoint)
        self.sam.to(device=self.device)

        # Create the mask generator for the instance segmentation model
        self.mask_generator = SamAutomaticMaskGenerator(
            model=self.sam,
            points_per_side=32, # Number of points per side for generating instance masks
            pred_iou_thresh=0.9, # IoU threshold for predicting instance masks
            stability_score_thresh=0.96, # Stability score threshold for instance masks
            crop_n_layers=1, # Number of layers to crop for generating instance masks
            crop_n_points_downscale_factor=2, # Downscale factor for cropping instance masks
            min_mask_region_area=100, # Minimum area for valid instance mask regions
        )

    def create_masks(self, frame):
        """
        Generates an instance mask for the given frame using the instance segmentation model.

        Args:
            frame (numpy.ndarray): Input frame to be segmented.

        Returns:
            numpy.ndarray: Instance mask generated by the model.
        """
        return self.mask_generator.generate(frame)
    
    def isolate_objects(self, frame, masks):
        """
        Extracts individual objects from the frame based on the provided instance masks.

        Args:
            frame (numpy.ndarray): Input frame containing the objects.
            masks (List[dict]): List of instance masks.

        Returns:
            List[numpy.ndarray]: Cropped objects extracted from the frame.
        """
        cropped_objects = []
        sorted_masks = sorted(masks, key=(lambda x: x['area']), reverse=True)

        for mask in sorted_masks:
            x, y, width, height = mask['bbox']
            cropped_frame = frame[y:y+height, x:x+width]
            mask_binary = (mask['segmentation'][y:y+height, x:x+width] > 0).astype(np.uint8) * 255
            mask_binary = cv2.cvtColor(mask_binary, cv2.COLOR_GRAY2BGR)  # Convert mask to 3 channels
            cropped_frame = cv2.bitwise_and(cropped_frame, mask_binary)
            cropped_objects.append(cropped_frame)

        return cropped_objects

